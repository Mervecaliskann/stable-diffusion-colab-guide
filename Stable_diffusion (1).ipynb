{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB5T8O92I-w_"
      },
      "outputs": [],
      "source": [
        "# --- ADIM 1: KURULUM VE HAZIRLIK ---\n",
        "print(\">>> Gerekli kÃ¼tÃ¼phaneler kuruluyor...\")\n",
        "!pip install diffusers transformers accelerate safetensors -q\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from google.colab import userdata\n",
        "import matplotlib.pyplot as plt\n",
        "print(\">>> Kurulum ve hazÄ±rlÄ±k tamamlandÄ±!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 2: MODELÄ° YÃœKLEME ---\n",
        "# Bu adÄ±m, internet hÄ±zÄ±na ve Colab yoÄŸunluÄŸuna gÃ¶re birkaÃ§ dakika sÃ¼rebilir.\n",
        "try:\n",
        "    print(\">>> Hugging Face'e baÄŸlanÄ±lÄ±yor ve model yÃ¼kleniyor...\")\n",
        "    token = userdata.get('HF_TOKEN')\n",
        "\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        token=token\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(\">>> Model baÅŸarÄ±yla yÃ¼klendi ve GPU'da hazÄ±r!\")\n",
        "    model_yuklendi = True # Modelin yÃ¼klendiÄŸini iÅŸaretleyelim\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Bir hata oluÅŸtu: {e}\")\n",
        "    print(\">>> LÃ¼tfen sol menÃ¼deki anahtar (ðŸ”‘) simgesinden HF_TOKEN'Ä±nÄ±zÄ± eklediÄŸinizden emin olun.\")\n",
        "    model_yuklendi = False"
      ],
      "metadata": {
        "id": "7sxcHO-nGhIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 3: SANAT YÃ–NETMENLÄ°ÄžÄ° (PROMPTLARI AYARLAMA) ---\n",
        "# Model baÅŸarÄ±yla yÃ¼klendiyse bu adÄ±ma geÃ§.\n",
        "if model_yuklendi:\n",
        "    # OLUMLU PROMPT: Ne gÃ¶rmek istiyoruz?\n",
        "    prompt = \"photo of a beautiful British shorthair cat wearing a tiny wizard hat, magical library in the background, cinematic, detailed, fantasy art\"\n",
        "\n",
        "    # NEGATÄ°F PROMPT: Neleri gÃ¶rmek istemiyoruz?\n",
        "    # Bu kÄ±sÄ±m, sonucun kalitesini ciddi ÅŸekilde artÄ±rÄ±r.\n",
        "    negative_prompt = \"blurry, ugly, deformed, distorted, poor quality, bad anatomy, extra limbs, missing limbs, text, watermark, signature\"\n",
        "\n",
        "    # Ayarlar\n",
        "    kalite_adimlari = 30      # Ne kadar detaylÄ± Ã§alÄ±ÅŸsÄ±n?\n",
        "    rehberlik_skalasi = 7.5  # Hayalimize ne kadar sadÄ±k kalsÄ±n?\n",
        "\n",
        "    # --- SÄ°HRÄ° BAÅžLATMA VE GÃ–RÃœNTÃœ OLUÅžTURMA ---\n",
        "    print(\"\\n>>> GÃ¶rÃ¼ntÃ¼ oluÅŸturuluyor... LÃ¼tfen bekleyin.\")\n",
        "\n",
        "    # pipe() fonksiyonunu bu sefer negative_prompt ile birlikte Ã§aÄŸÄ±rÄ±yoruz.\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=kalite_adimlari,\n",
        "        guidance_scale=rehberlik_skalasi\n",
        "    ).images[0]\n",
        "\n",
        "    print(\">>> Ä°ÅŸte eseriniz!\")\n",
        "\n",
        "    # --- ESERÄ° SERGÄ°LEME ---\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iDKpT3KeGjTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}