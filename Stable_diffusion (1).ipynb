{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB5T8O92I-w_"
      },
      "outputs": [],
      "source": [
        "# --- ADIM 1: KURULUM VE HAZIRLIK ---\n",
        "print(\">>> Gerekli kütüphaneler kuruluyor...\")\n",
        "!pip install diffusers transformers accelerate safetensors -q\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from google.colab import userdata\n",
        "import matplotlib.pyplot as plt\n",
        "print(\">>> Kurulum ve hazırlık tamamlandı!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 2: MODELİ YÜKLEME ---\n",
        "# Bu adım, internet hızına ve Colab yoğunluğuna göre birkaç dakika sürebilir.\n",
        "try:\n",
        "    print(\">>> Hugging Face'e bağlanılıyor ve model yükleniyor...\")\n",
        "    token = userdata.get('HF_TOKEN')\n",
        "\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        token=token\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(\">>> Model başarıyla yüklendi ve GPU'da hazır!\")\n",
        "    model_yuklendi = True # Modelin yüklendiğini işaretleyelim\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Bir hata oluştu: {e}\")\n",
        "    print(\">>> Lütfen sol menüdeki anahtar (🔑) simgesinden HF_TOKEN'ınızı eklediğinizden emin olun.\")\n",
        "    model_yuklendi = False"
      ],
      "metadata": {
        "id": "7sxcHO-nGhIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADIM 3: SANAT YÖNETMENLİĞİ (PROMPTLARI AYARLAMA) ---\n",
        "# Model başarıyla yüklendiyse bu adıma geç.\n",
        "if model_yuklendi:\n",
        "    # OLUMLU PROMPT: Ne görmek istiyoruz?\n",
        "    prompt = \"photo of a beautiful British shorthair cat wearing a tiny wizard hat, magical library in the background, cinematic, detailed, fantasy art\"\n",
        "\n",
        "    # NEGATİF PROMPT: Neleri görmek istemiyoruz?\n",
        "    # Bu kısım, sonucun kalitesini ciddi şekilde artırır.\n",
        "    negative_prompt = \"blurry, ugly, deformed, distorted, poor quality, bad anatomy, extra limbs, missing limbs, text, watermark, signature\"\n",
        "\n",
        "    # Ayarlar\n",
        "    kalite_adimlari = 30      # Ne kadar detaylı çalışsın?\n",
        "    rehberlik_skalasi = 7.5  # Hayalimize ne kadar sadık kalsın?\n",
        "\n",
        "    # --- SİHRİ BAŞLATMA VE GÖRÜNTÜ OLUŞTURMA ---\n",
        "    print(\"\\n>>> Görüntü oluşturuluyor... Lütfen bekleyin.\")\n",
        "\n",
        "    # pipe() fonksiyonunu bu sefer negative_prompt ile birlikte çağırıyoruz.\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=kalite_adimlari,\n",
        "        guidance_scale=rehberlik_skalasi\n",
        "    ).images[0]\n",
        "\n",
        "    print(\">>> İşte eseriniz!\")\n",
        "\n",
        "    # --- ESERİ SERGİLEME ---\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iDKpT3KeGjTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}